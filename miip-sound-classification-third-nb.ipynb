{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":267422,"sourceType":"datasetVersion","datasetId":110374},{"sourceId":5829288,"sourceType":"datasetVersion","datasetId":3350462}],"dockerImageVersionId":30302,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nimport wave\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom IPython.display import Audio\n\nimport librosa\nimport librosa.display\n\nfrom keras.utils import np_utils\nfrom keras.layers.merge import concatenate\nfrom tensorflow.keras.models import Sequential, Model, load_model\n\nfrom tensorflow.keras.layers import Conv1D, Conv2D, SeparableConv1D, MaxPooling1D, MaxPooling2D\nfrom tensorflow.keras.layers import Input, add, Flatten, Dense, BatchNormalization, Dropout, LSTM, GRU\nfrom tensorflow.keras.layers import GlobalMaxPooling1D, GlobalMaxPooling2D, Activation, LeakyReLU, ReLU\n\n# from tensorflow.keras.layers import Embedding,LSTM,GRU,Dense,MaxPooling1D,Dropout, Input\n# from tensorflow.keras.layers import LeakyReLU,ReLU,Flatten,concatenate,Bidirectional,TimeDistributed \n# from tensorflow.keras.layers import add,Conv1D,SeparableConv1D, GlobalMaxPooling2D,GlobalMaxPooling1D\n# from tensorflow.keras.layers import Conv2D,Input,Activation,BatchNormalization,MaxPooling2D\n\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,matthews_corrcoef\nfrom sklearn.metrics import cohen_kappa_score,roc_auc_score,confusion_matrix,classification_report","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:42:22.059678Z","iopub.execute_input":"2023-12-04T12:42:22.060150Z","iopub.status.idle":"2023-12-04T12:42:29.571148Z","shell.execute_reply.started":"2023-12-04T12:42:22.060060Z","shell.execute_reply":"2023-12-04T12:42:29.570091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"audio_data = '/kaggle/input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/'","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:42:29.573873Z","iopub.execute_input":"2023-12-04T12:42:29.575622Z","iopub.status.idle":"2023-12-04T12:42:29.580409Z","shell.execute_reply.started":"2023-12-04T12:42:29.575589Z","shell.execute_reply":"2023-12-04T12:42:29.579179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"audio_data","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:42:29.581664Z","iopub.execute_input":"2023-12-04T12:42:29.581966Z","iopub.status.idle":"2023-12-04T12:42:29.600741Z","shell.execute_reply.started":"2023-12-04T12:42:29.581939Z","shell.execute_reply":"2023-12-04T12:42:29.599733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patient_data=pd.read_csv('/kaggle/input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/patient_diagnosis.csv',names=['pid','disease'])","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:42:29.601966Z","iopub.execute_input":"2023-12-04T12:42:29.602254Z","iopub.status.idle":"2023-12-04T12:42:29.619878Z","shell.execute_reply.started":"2023-12-04T12:42:29.602225Z","shell.execute_reply":"2023-12-04T12:42:29.619120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diagnosis_df = pd.read_csv('../input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/patient_diagnosis.csv', names=['patient_id', 'disease'])\ndiagnosis_df.head(4)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:42:29.622420Z","iopub.execute_input":"2023-12-04T12:42:29.622703Z","iopub.status.idle":"2023-12-04T12:42:29.638724Z","shell.execute_reply.started":"2023-12-04T12:42:29.622677Z","shell.execute_reply":"2023-12-04T12:42:29.637863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (diagnosis_df.disease.value_counts())\nprint ('')\nprint (diagnosis_df.disease.value_counts(normalize=True) *100)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:42:29.639770Z","iopub.execute_input":"2023-12-04T12:42:29.640085Z","iopub.status.idle":"2023-12-04T12:42:29.653079Z","shell.execute_reply.started":"2023-12-04T12:42:29.640059Z","shell.execute_reply":"2023-12-04T12:42:29.651964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(diagnosis_df.disease)\nplt.grid(axis = 'y',color = 'green', linestyle = '--', linewidth = 0.5)\nplt.xticks(rotation=90)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:42:29.654246Z","iopub.execute_input":"2023-12-04T12:42:29.654516Z","iopub.status.idle":"2023-12-04T12:42:29.936796Z","shell.execute_reply.started":"2023-12-04T12:42:29.654491Z","shell.execute_reply":"2023-12-04T12:42:29.935790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path='/kaggle/input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/'\nfiles=[s.split('.')[0] for s in os.listdir(path) if '.txt' in s]","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:42:29.938031Z","iopub.execute_input":"2023-12-04T12:42:29.938304Z","iopub.status.idle":"2023-12-04T12:42:30.029739Z","shell.execute_reply.started":"2023-12-04T12:42:29.938279Z","shell.execute_reply":"2023-12-04T12:42:30.028972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files[:10]","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:42:30.030946Z","iopub.execute_input":"2023-12-04T12:42:30.031274Z","iopub.status.idle":"2023-12-04T12:42:30.037783Z","shell.execute_reply.started":"2023-12-04T12:42:30.031217Z","shell.execute_reply":"2023-12-04T12:42:30.036878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_noise(data,x):\n    noise = np.random.randn(len(data))\n    data_noise = data + x * noise\n    return data_noise\n\ndef shift(data,x):\n    return np.roll(data, x)\n\ndef stretch(data, rate):\n    data = librosa.effects.time_stretch(data, rate)\n    return data\n\ndef pitch_shift (data , rate):\n    data = librosa.effects.pitch_shift(data, sr=220250, n_steps=rate)\n    return data","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:42:30.039213Z","iopub.execute_input":"2023-12-04T12:42:30.040078Z","iopub.status.idle":"2023-12-04T12:42:30.047386Z","shell.execute_reply.started":"2023-12-04T12:42:30.040036Z","shell.execute_reply":"2023-12-04T12:42:30.046397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_audio(audio_path):\n    y, sr = librosa.load(audio_path)\n    y_noise = add_noise(y , 0.0008)\n    y_shift = shift(y,3200)\n    y_stretch_1 = stretch(y, 1.2)\n    y_stretch_2 = stretch(y, 0.8)\n    y_pitch_shift = pitch_shift(y, 3)\n    \n    plt.figure(figsize=(20, 8))\n    \n    plt.subplot(3,2,1)\n    librosa.display.waveshow(y, sr=sr)\n    plt.title('orginal')\n\n    plt.subplot(3,2,2)\n    librosa.display.waveshow(y_noise, sr=sr)\n    plt.title('noise')\n\n    plt.subplot(3,2,3)\n    librosa.display.waveshow(y_shift, sr=sr)\n    plt.title('shift')\n    \n    plt.subplot(3,2,4)\n    librosa.display.waveshow(y_stretch_1, sr=sr)\n    plt.title('stretch 1')\n    \n    plt.subplot(3,2,5)\n    librosa.display.waveshow(y_stretch_2, sr=sr)\n    plt.title('stretch 2')\n    \n    plt.subplot(3,2,6)\n    librosa.display.waveshow(y_pitch_shift, sr=sr)\n    plt.title('pitch shift')\n\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:42:30.048576Z","iopub.execute_input":"2023-12-04T12:42:30.048940Z","iopub.status.idle":"2023-12-04T12:42:30.060564Z","shell.execute_reply.started":"2023-12-04T12:42:30.048912Z","shell.execute_reply":"2023-12-04T12:42:30.059732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_audio_features(audio_path):\n    y, sr = librosa.load(audio_path)\n    y_noise = add_noise(y , 0.0008)\n    y_shift = shift(y,3200)\n    y_stretch_1 = stretch(y, 1.2)\n    y_stretch_2 = stretch(y, 0.8)\n    y_pitch_shift = pitch_shift(y, 3)\n    \n    y = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=50)\n    y_noise = librosa.feature.mfcc(y=y_noise, sr=sr, n_mfcc=50)\n    y_shift = librosa.feature.mfcc(y=y_shift, sr=sr, n_mfcc=50)\n    y_stretch_1 = librosa.feature.mfcc(y=y_stretch_1, sr=sr, n_mfcc=50)\n    y_stretch_2 = librosa.feature.mfcc(y=y_stretch_2, sr=sr, n_mfcc=50)\n    y_pitch_shift = librosa.feature.mfcc(y=y_pitch_shift, sr=sr, n_mfcc=50)\n    \n    plt.figure(figsize=(20, 8))\n    \n    plt.subplot(3,2,1)\n    librosa.display.specshow(librosa.power_to_db(y,ref=np.max),\n                             y_axis='mel',\n                             fmax=8000,\n                             x_axis='time')\n    plt.colorbar(format='%+2.0f dB')\n    plt.title('orginal')\n\n    plt.subplot(3,2,2)\n    librosa.display.specshow(librosa.power_to_db(y_noise,ref=np.max),\n                             y_axis='mel',\n                             fmax=8000,\n                             x_axis='time')\n    plt.colorbar(format='%+2.0f dB')\n    plt.title('noise')\n\n    plt.subplot(3,2,3)\n    librosa.display.specshow(librosa.power_to_db(y_shift,ref=np.max),\n                             y_axis='mel',\n                             fmax=8000,\n                             x_axis='time')\n    plt.colorbar(format='%+2.0f dB')\n    plt.title('shift')\n    \n    plt.subplot(3,2,4)\n    librosa.display.specshow(librosa.power_to_db(y_stretch_1,ref=np.max),\n                             y_axis='mel',\n                             fmax=8000,\n                             x_axis='time')\n    plt.colorbar(format='%+2.0f dB')\n    plt.title('stretch 1')\n    \n    plt.subplot(3,2,5)\n    librosa.display.specshow(librosa.power_to_db(y_stretch_2,ref=np.max),\n                             y_axis='mel',\n                             fmax=8000,\n                             x_axis='time')\n    plt.colorbar(format='%+2.0f dB')\n    plt.title('stretch 2')\n    \n    plt.subplot(3,2,6)\n    librosa.display.specshow(librosa.power_to_db(y_pitch_shift,ref=np.max),\n                             y_axis='mel',\n                             fmax=8000,\n                             x_axis='time')\n    plt.colorbar(format='%+2.0f dB')\n    plt.title('pitch shift')\n    \n    \n\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:42:30.061689Z","iopub.execute_input":"2023-12-04T12:42:30.062026Z","iopub.status.idle":"2023-12-04T12:42:30.080694Z","shell.execute_reply.started":"2023-12-04T12:42:30.061997Z","shell.execute_reply":"2023-12-04T12:42:30.079697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_audio('/kaggle/input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/104_1b1_Lr_sc_Litt3200.wav')","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:42:30.081964Z","iopub.execute_input":"2023-12-04T12:42:30.082362Z","iopub.status.idle":"2023-12-04T12:42:36.438963Z","shell.execute_reply.started":"2023-12-04T12:42:30.082327Z","shell.execute_reply":"2023-12-04T12:42:36.437878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_audio_features('/kaggle/input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/104_1b1_Lr_sc_Litt3200.wav')","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:42:36.445835Z","iopub.execute_input":"2023-12-04T12:42:36.446311Z","iopub.status.idle":"2023-12-04T12:42:39.455331Z","shell.execute_reply.started":"2023-12-04T12:42:36.446274Z","shell.execute_reply":"2023-12-04T12:42:39.454349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mfccs_feature_exteraction(dir_):\n    '''\n        Extract MFCC feature from the Sound data from the audio data. \n        Augmentation of sound data by adding Noise, streaching and shifting.\n        50 features are extracted from each audio data and used to train the model. \n        Also, we remove .wav files with patient_id 103,108, and 115 to solve data imbalance, because they have unique lables. \n        \n        Args: dir_: Input directory to the Sound input file.\n        \n        Returns:\n            X_data: Array of features extracted from the sound file.\n            y_data: Array of target Labels.\n    '''\n    X_=[]\n    y_=[]\n    \n    COPD=[]\n    copd_count=0\n    \n    data = diagnosis_df\n    features = 52\n    \n    for soundDir in (os.listdir(dir_)):\n        if soundDir[-3:]=='wav'and soundDir[:3]!='103'and soundDir[:3]!='108'and soundDir[:3]!='115':\n\n            p = list(data[data['patient_id']==int(soundDir[:3])]['disease'])[0]\n            if (p=='COPD'):\n                if (soundDir[:6] in COPD) and copd_count<2:\n                    data_x, sampling_rate = librosa.load(dir_+soundDir,res_type='kaiser_fast')\n                    mfccs = np.mean(librosa.feature.mfcc(y=data_x, sr=sampling_rate, n_mfcc=features).T,axis=0)\n                    COPD.append(soundDir[:6])\n                    copd_count+=1\n                    X_.append(mfccs)\n                    y_.append(list(data[data['patient_id']==int(soundDir[:3])]['disease'])[0])\n                    \n                if (soundDir[:6] not in COPD):\n                    data_x, sampling_rate = librosa.load(dir_+soundDir,res_type='kaiser_fast')\n                    mfccs = np.mean(librosa.feature.mfcc(y=data_x, sr=sampling_rate, n_mfcc=features).T,axis=0)\n                    COPD.append(soundDir[:6])\n                    copd_count=0\n                    X_.append(mfccs)\n                    y_.append(list(data[data['patient_id']==int(soundDir[:3])]['disease'])[0])\n                \n            if (p!='COPD'):\n                if ((p == 'Bronchiectasis') or (p == 'Bronchiolitis')):\n                    data_x, sampling_rate = librosa.load(dir_+soundDir,res_type='kaiser_fast')\n                    mfccs = np.mean(librosa.feature.mfcc(y=data_x, sr=sampling_rate, n_mfcc=features).T,axis=0)\n                    X_.append(mfccs)\n                    y_.append('Bronchiolitis')\n            \n                    data_noise = add_noise(data_x,0.001)\n                    mfccs_noise = np.mean(librosa.feature.mfcc(y=data_noise, sr=sampling_rate, n_mfcc=features).T,axis=0)\n                    X_.append(mfccs_noise)\n                    y_.append('Bronchiolitis')\n\n                    data_shift = shift(data_x,1600)\n                    mfccs_shift = np.mean(librosa.feature.mfcc(y=data_shift, sr=sampling_rate, n_mfcc=features).T,axis=0)\n                    X_.append(mfccs_shift)\n                    y_.append('Bronchiolitis')\n                    \n                    data_stretch = stretch(data_x,1.2)\n                    mfccs_stretch = np.mean(librosa.feature.mfcc(y=data_stretch, sr=sampling_rate, n_mfcc=features).T,axis=0)\n                    X_.append(mfccs_stretch)\n                    y_.append('Bronchiolitis')\n                    \n                    data_stretch_2 = stretch(data_x,0.8)\n                    mfccs_stretch_2 = np.mean(librosa.feature.mfcc(y=data_stretch_2, sr=sampling_rate, n_mfcc=features).T,axis=0)\n                    X_.append(mfccs_stretch_2)\n                    y_.append('Bronchiolitis')\n                    \n                    data_pitch_shift = pitch_shift(data_x,3)\n                    mfccs_stretch = np.mean(librosa.feature.melspectrogram(y=data_pitch_shift, sr=sampling_rate, n_mels=features).T,axis=0)\n                    X_.append(mfccs_stretch)\n                    y_.append('Bronchiolitis')\n                    \n                else: \n                    data_x, sampling_rate = librosa.load(dir_+soundDir,res_type='kaiser_fast')\n                    mfccs = np.mean(librosa.feature.mfcc(y=data_x, sr=sampling_rate, n_mfcc=features).T,axis=0)\n                    X_.append(mfccs)\n                    y_.append(list(data[data['patient_id']==int(soundDir[:3])]['disease'])[0])\n            \n                    data_noise = add_noise(data_x,0.001)\n                    mfccs_noise = np.mean(librosa.feature.mfcc(y=data_noise, sr=sampling_rate, n_mfcc=features).T,axis=0)\n                    X_.append(mfccs_noise)\n                    y_.append(p)\n\n                    data_shift = shift(data_x,1600)\n                    mfccs_shift = np.mean(librosa.feature.mfcc(y=data_shift, sr=sampling_rate, n_mfcc=features).T,axis=0)\n                    X_.append(mfccs_shift)\n                    y_.append(p)\n                    \n                    data_stretch = stretch(data_x,1.2)\n                    mfccs_stretch = np.mean(librosa.feature.mfcc(y=data_stretch, sr=sampling_rate, n_mfcc=features).T,axis=0)\n                    X_.append(mfccs_stretch)\n                    y_.append(p)\n                    \n                    data_stretch_2 = stretch(data_x,0.8)\n                    mfccs_stretch_2 = np.mean(librosa.feature.mfcc(y=data_stretch_2, sr=sampling_rate, n_mfcc=features).T,axis=0)\n                    X_.append(mfccs_stretch_2)\n                    y_.append(p)\n                    \n                    data_pitch_shift = pitch_shift(data_x,3)\n                    mfccs_stretch = np.mean(librosa.feature.melspectrogram(y=data_pitch_shift, sr=sampling_rate, n_mels=features).T,axis=0)\n                    X_.append(mfccs_stretch)\n                    y_.append(p)\n                    \n                    \n                \n    X_data = np.array(X_)\n    y_data = np.array(y_)\n\n    \n    return X_data, y_data ","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:42:39.456710Z","iopub.execute_input":"2023-12-04T12:42:39.457052Z","iopub.status.idle":"2023-12-04T12:42:39.492742Z","shell.execute_reply.started":"2023-12-04T12:42:39.457023Z","shell.execute_reply":"2023-12-04T12:42:39.491799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_mfccs, y = mfccs_feature_exteraction(audio_data)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:42:39.494271Z","iopub.execute_input":"2023-12-04T12:42:39.494896Z","iopub.status.idle":"2023-12-04T12:47:33.871543Z","shell.execute_reply.started":"2023-12-04T12:42:39.494858Z","shell.execute_reply":"2023-12-04T12:47:33.869737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def augmented_lables_count(lables):\n    unique, counts = np.unique(lables, return_counts=True)\n    data_count = dict(zip(unique, counts))\n\n    data = data_count\n\n    courses = list(data.keys())\n    values = list(data.values())\n\n    fig = plt.figure(figsize = (10, 5))\n\n    # creating the bar plot\n    plt.bar(courses, values, color =['orange','green','blue','red','yellow','black'],\n            width = 0.4)\n\n    plt.xlabel(\"Diseases\")\n    plt.ylabel(\"Count\")\n    plt.title(\"Count of each disease\")\n    plt.show()\n\n    print (data_count)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:47:33.874042Z","iopub.execute_input":"2023-12-04T12:47:33.874573Z","iopub.status.idle":"2023-12-04T12:47:33.887386Z","shell.execute_reply.started":"2023-12-04T12:47:33.874522Z","shell.execute_reply":"2023-12-04T12:47:33.886047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augmented_lables_count(y)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:47:33.889558Z","iopub.execute_input":"2023-12-04T12:47:33.890058Z","iopub.status.idle":"2023-12-04T12:47:34.116715Z","shell.execute_reply.started":"2023-12-04T12:47:33.890007Z","shell.execute_reply":"2023-12-04T12:47:34.115465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:47:34.118573Z","iopub.execute_input":"2023-12-04T12:47:34.119317Z","iopub.status.idle":"2023-12-04T12:47:34.134487Z","shell.execute_reply.started":"2023-12-04T12:47:34.119276Z","shell.execute_reply":"2023-12-04T12:47:34.133464Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ny = np.array(y)\n\n# Reshape your array\ny_data_encode = y.reshape(y.shape[0], 1)\n\n# Create an array for conditions to keep\nconditions = (y_data_encode == 'COPD') | (y_data_encode == 'Healthy')\n\n# Get the indices of the rows that meet the conditions\nindices = np.where(conditions)[0]\n\n# Select the corresponding x values\nx_data = x_mfccs[indices]\n\n# Delete rows that do not meet the conditions\ny_data_encode = np.delete(y_data_encode, np.where(~conditions), axis=0)\n\n# Create a new array for encoded labels\nencoded_y = np.zeros(y_data_encode.shape)\n\n# Fill the new array based on the conditions\nencoded_y[y_data_encode == 'COPD'] = 0\nencoded_y[y_data_encode == 'Healthy'] = 1\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:47:34.136122Z","iopub.execute_input":"2023-12-04T12:47:34.136479Z","iopub.status.idle":"2023-12-04T12:47:34.144880Z","shell.execute_reply.started":"2023-12-04T12:47:34.136450Z","shell.execute_reply":"2023-12-04T12:47:34.143980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_y","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:47:34.146234Z","iopub.execute_input":"2023-12-04T12:47:34.147196Z","iopub.status.idle":"2023-12-04T12:47:34.161684Z","shell.execute_reply.started":"2023-12-04T12:47:34.147155Z","shell.execute_reply":"2023-12-04T12:47:34.160746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mfccs_features = np.array(x_data)\nlables = np.array(encoded_y)\n\nmfccs_features.shape , lables.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:47:34.162967Z","iopub.execute_input":"2023-12-04T12:47:34.163246Z","iopub.status.idle":"2023-12-04T12:47:34.170845Z","shell.execute_reply.started":"2023-12-04T12:47:34.163212Z","shell.execute_reply":"2023-12-04T12:47:34.169858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mfccs_features = mfccs_features[:-1]\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:47:34.172098Z","iopub.execute_input":"2023-12-04T12:47:34.172459Z","iopub.status.idle":"2023-12-04T12:47:34.179642Z","shell.execute_reply.started":"2023-12-04T12:47:34.172422Z","shell.execute_reply":"2023-12-04T12:47:34.178799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mfcc_train, mfcc_val, lables_train, lables_val  = train_test_split(mfccs_features, lables, test_size=0.175, random_state=10)\nmfcc_train, mfcc_test, lables_train, lables_test = train_test_split(mfcc_train, lables_train, test_size=0.075, random_state=10)\n\nprint (mfcc_train.shape, mfcc_val.shape, mfcc_test.shape)\nprint (lables_train.shape, lables_val.shape, lables_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:47:34.180894Z","iopub.execute_input":"2023-12-04T12:47:34.181173Z","iopub.status.idle":"2023-12-04T12:47:34.190283Z","shell.execute_reply.started":"2023-12-04T12:47:34.181147Z","shell.execute_reply":"2023-12-04T12:47:34.189365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mfccs_features","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:47:34.191630Z","iopub.execute_input":"2023-12-04T12:47:34.192018Z","iopub.status.idle":"2023-12-04T12:47:34.199343Z","shell.execute_reply.started":"2023-12-04T12:47:34.191977Z","shell.execute_reply":"2023-12-04T12:47:34.198376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss_curves(history):\n  \"\"\"\n  Returns separate loss curves for training and validation metrics.\n  Args:\n    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)\n  \"\"\" \n  loss = history.history['loss']\n  val_loss = history.history['val_loss']\n\n  accuracy = history.history['accuracy']\n  val_accuracy = history.history['val_accuracy']\n\n  epochs = range(len(history.history['loss']))\n\n  # Plot loss\n#   plt.plot(epochs, loss, label='training_loss')\n#   plt.plot(epochs, val_loss, label='val_loss')\n#   plt.title('Loss')\n#   plt.xlabel('Epochs')\n#   plt.legend()\n#   plt.grid()\n\n\n  # Plot accuracy\n  plt.figure()\n  plt.grid()\n  plt.plot(epochs, accuracy, label='training_accuracy')\n  plt.plot(epochs, val_accuracy, label='val_accuracy')\n  plt.title('Accuracy')\n  plt.xlabel('Epochs')\n  plt.legend();\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:47:34.200466Z","iopub.execute_input":"2023-12-04T12:47:34.201012Z","iopub.status.idle":"2023-12-04T12:47:34.208913Z","shell.execute_reply.started":"2023-12-04T12:47:34.200984Z","shell.execute_reply":"2023-12-04T12:47:34.207792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Random seed","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:47:34.210806Z","iopub.execute_input":"2023-12-04T12:47:34.211237Z","iopub.status.idle":"2023-12-04T12:47:34.220041Z","shell.execute_reply.started":"2023-12-04T12:47:34.211182Z","shell.execute_reply":"2023-12-04T12:47:34.219215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_gru = np.expand_dims(mfcc_train,axis=1)\nx_val_gru = np.expand_dims(mfcc_val,axis=1)\nx_test_gru = np.expand_dims(mfcc_test,axis=1)\n\ny_train_gru = np.expand_dims(lables_train,axis=1)\ny_val_gru = np.expand_dims(lables_val,axis=1)\ny_test_gru = np.expand_dims(lables_test,axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:47:34.221158Z","iopub.execute_input":"2023-12-04T12:47:34.221465Z","iopub.status.idle":"2023-12-04T12:47:34.228357Z","shell.execute_reply.started":"2023-12-04T12:47:34.221438Z","shell.execute_reply":"2023-12-04T12:47:34.227342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Input_Sample = Input(shape=(1,52))\n\nmodel_conv = Conv1D(256, kernel_size=2, strides=1, padding='same', activation='relu')(Input_Sample)\nmodel_conv = MaxPooling1D(pool_size=2, strides = 2, padding = 'same')(model_conv)\nmodel_conv = BatchNormalization()(model_conv)\n\nmodel_conv = Conv1D(512, kernel_size=2, strides=1, padding='same', activation='relu')(model_conv)\nmodel_conv = MaxPooling1D(pool_size=2, strides = 2, padding = 'same')(model_conv)\nmodel_conv = BatchNormalization()(model_conv)\n\nmodel_2_1 = GRU(32,return_sequences=True,activation='tanh',go_backwards=True)(model_conv)\nmodel_2 = GRU(128,return_sequences=True, activation='tanh',go_backwards=True)(model_2_1)\n\nmodel_3 = GRU(64,return_sequences=True,activation='tanh',go_backwards=True)(model_conv)\nmodel_3 = GRU(128,return_sequences=True, activation='tanh',go_backwards=True)(model_3)\n\nmodel_x = GRU(64,return_sequences=True,activation='tanh',go_backwards=True)(model_conv)\nmodel_x = GRU(128,return_sequences=True, activation='tanh',go_backwards=True)(model_x)\n\nmodel_add_1 = add([model_3,model_2,model_x])\n\nmodel_5 = GRU(128,return_sequences=True,activation='tanh',go_backwards=True)(model_add_1)\nmodel_5 = GRU(32,return_sequences=True, activation='tanh',go_backwards=True)(model_5)\n\nmodel_6 = GRU(64,return_sequences=True,activation='tanh',go_backwards=True)(model_add_1)\nmodel_6 = GRU(32,return_sequences=True, activation='tanh',go_backwards=True)(model_6)\n\nmodel_add_2 = add([model_5,model_6,model_2_1])\n\n\nmodel_7 = Dense(32, activation=None)(model_add_2)\nmodel_7 = LeakyReLU()(model_7)\nmodel_7 = Dense(128, activation=None)(model_7)\nmodel_7 = LeakyReLU()(model_7)\n\nmodel_9 = Dense(64, activation=None)(model_add_2)\nmodel_9 = LeakyReLU()(model_9)\nmodel_9 = Dense(128, activation=None)(model_9)\nmodel_9 = LeakyReLU()(model_9)\n\nmodel_add_3 = add([model_7,model_9])\n\nmodel_10 = Dense(64, activation=None)(model_add_3)\nmodel_10 = LeakyReLU()(model_10)\n\nmodel_10 = Dense(32, activation=None)(model_10)\nmodel_10 = LeakyReLU()(model_10)\n\nmodel_10 = Dense(1, activation=\"sigmoid\")(model_10)\n\ngru_model = Model(inputs=Input_Sample, outputs=model_10)\n\ngru_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:47:34.229705Z","iopub.execute_input":"2023-12-04T12:47:34.230043Z","iopub.status.idle":"2023-12-04T12:47:39.229970Z","shell.execute_reply.started":"2023-12-04T12:47:34.230014Z","shell.execute_reply":"2023-12-04T12:47:39.228750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(gru_model, \"gru_model.png\", show_shapes=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:47:39.231457Z","iopub.execute_input":"2023-12-04T12:47:39.232056Z","iopub.status.idle":"2023-12-04T12:47:40.426181Z","shell.execute_reply.started":"2023-12-04T12:47:39.232024Z","shell.execute_reply":"2023-12-04T12:47:40.424958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimiser = tf.keras.optimizers.Adam(learning_rate = 0.0001)\ngru_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\ncb = [EarlyStopping(patience=300,monitor='accuracy',mode='max',restore_best_weights=True),\n      ModelCheckpoint(\"/kaggle/working/diagnosis_GRU_CNN_1.h5\",save_best_only=True)]","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:47:40.427932Z","iopub.execute_input":"2023-12-04T12:47:40.428305Z","iopub.status.idle":"2023-12-04T12:47:40.450042Z","shell.execute_reply.started":"2023-12-04T12:47:40.428266Z","shell.execute_reply":"2023-12-04T12:47:40.449027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = gru_model.fit(x_train_gru, y_train_gru, batch_size=8, epochs=50, validation_data=(x_val_gru, y_val_gru), callbacks = cb)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:47:40.451262Z","iopub.execute_input":"2023-12-04T12:47:40.451565Z","iopub.status.idle":"2023-12-04T12:48:41.940316Z","shell.execute_reply.started":"2023-12-04T12:47:40.451524Z","shell.execute_reply":"2023-12-04T12:48:41.939298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Exchange test for val after training for once\n#Cross validation ","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:48:41.941829Z","iopub.execute_input":"2023-12-04T12:48:41.942154Z","iopub.status.idle":"2023-12-04T12:48:41.946312Z","shell.execute_reply.started":"2023-12-04T12:48:41.942119Z","shell.execute_reply":"2023-12-04T12:48:41.945230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gru_model.evaluate(x_train_gru, y_train_gru)\n\nplot_loss_curves(history)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:48:41.947503Z","iopub.execute_input":"2023-12-04T12:48:41.947889Z","iopub.status.idle":"2023-12-04T12:48:42.344480Z","shell.execute_reply.started":"2023-12-04T12:48:41.947825Z","shell.execute_reply":"2023-12-04T12:48:42.343356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import GRU\n\n# Assume you have a trained GRU model in 'model'\ngru_model.save('my_gru_model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:48:42.345980Z","iopub.execute_input":"2023-12-04T12:48:42.346690Z","iopub.status.idle":"2023-12-04T12:48:42.504091Z","shell.execute_reply.started":"2023-12-04T12:48:42.346641Z","shell.execute_reply":"2023-12-04T12:48:42.503063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = [\"COPD\" , \"Healthy\"]\n\npreds = gru_model.predict(x_test_gru)\nclasspreds = [np.argmax(t) for t in preds ]\ny_testclass = [np.argmax(t) for t in y_test_gru]\ncm = confusion_matrix(y_testclass, classpreds)\n\nplt.figure(figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\nax = sns.heatmap(cm, cmap='Blues', annot=True, fmt='d', xticklabels=classes, yticklabels=classes)\n\nplt.title('')\nplt.xlabel('Prediction')\nplt.ylabel('Truth')\nplt.show(ax)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:48:42.505750Z","iopub.execute_input":"2023-12-04T12:48:42.506601Z","iopub.status.idle":"2023-12-04T12:48:45.502220Z","shell.execute_reply.started":"2023-12-04T12:48:42.506558Z","shell.execute_reply":"2023-12-04T12:48:45.501197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nunique_classes = np.unique(y_testclass)\nlen(unique_classes)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:48:45.503665Z","iopub.execute_input":"2023-12-04T12:48:45.504028Z","iopub.status.idle":"2023-12-04T12:48:45.511132Z","shell.execute_reply.started":"2023-12-04T12:48:45.503995Z","shell.execute_reply":"2023-12-04T12:48:45.510070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_names = [str(class_) for class_ in unique_classes]\ntarget_names = tuple(str(class_) for class_ in unique_classes)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:48:45.512688Z","iopub.execute_input":"2023-12-04T12:48:45.513074Z","iopub.status.idle":"2023-12-04T12:48:45.519160Z","shell.execute_reply.started":"2023-12-04T12:48:45.513033Z","shell.execute_reply":"2023-12-04T12:48:45.517947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_testclass, classpreds, target_names=target_names))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:48:45.520407Z","iopub.execute_input":"2023-12-04T12:48:45.520730Z","iopub.status.idle":"2023-12-04T12:48:45.534093Z","shell.execute_reply.started":"2023-12-04T12:48:45.520698Z","shell.execute_reply":"2023-12-04T12:48:45.533096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_testclass, classpreds, labels=[0, 1]))\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:48:45.535535Z","iopub.execute_input":"2023-12-04T12:48:45.535879Z","iopub.status.idle":"2023-12-04T12:48:45.550153Z","shell.execute_reply.started":"2023-12-04T12:48:45.535846Z","shell.execute_reply":"2023-12-04T12:48:45.549025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\n\naccuracy = accuracy_score(y_testclass, classpreds)\nprint(f'Accuracy: {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:48:45.557644Z","iopub.execute_input":"2023-12-04T12:48:45.558007Z","iopub.status.idle":"2023-12-04T12:48:45.565001Z","shell.execute_reply.started":"2023-12-04T12:48:45.557975Z","shell.execute_reply":"2023-12-04T12:48:45.563867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = gru_model.fit(x_train_gru, y_train_gru, batch_size=8, epochs=50, validation_data=(x_test_gru, y_test_gru), callbacks = cb)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:48:45.566504Z","iopub.execute_input":"2023-12-04T12:48:45.566974Z","iopub.status.idle":"2023-12-04T12:49:21.497890Z","shell.execute_reply.started":"2023-12-04T12:48:45.566938Z","shell.execute_reply":"2023-12-04T12:49:21.497074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"gru_model.evaluate(x_test_gru, y_test_gru)\n\nplot_loss_curves(history)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:49:21.499408Z","iopub.execute_input":"2023-12-04T12:49:21.500153Z","iopub.status.idle":"2023-12-04T12:49:21.759037Z","shell.execute_reply.started":"2023-12-04T12:49:21.500112Z","shell.execute_reply":"2023-12-04T12:49:21.757771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cross Validation","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nmfccs_features = np.expand_dims(mfccs_features,axis=1)\nlables = np.expand_dims(lables, axis=1)\nkf = KFold(n_splits=5, shuffle=True)\n\n# For each fold\nfor train_index, test_index in kf.split(mfccs_features):\n   # Split the data\n   X_train, X_test = mfccs_features[train_index], mfccs_features[test_index]\n   y_train, y_test = lables[train_index], lables[test_index]\n\n   gru_model.fit(X_train, y_train, epochs=10, verbose=0)\n\n   loss = gru_model.evaluate(X_test, y_test, verbose=0)\n   print(f'Test loss: {loss}')","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:49:21.760278Z","iopub.execute_input":"2023-12-04T12:49:21.760582Z","iopub.status.idle":"2023-12-04T12:49:30.871920Z","shell.execute_reply.started":"2023-12-04T12:49:21.760551Z","shell.execute_reply":"2023-12-04T12:49:30.870875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Random seed\nGithub","metadata":{}},{"cell_type":"markdown","source":"## XAI: LRP","metadata":{}},{"cell_type":"markdown","source":"Relevance Filter","metadata":{}},{"cell_type":"code","source":"\"\"\"Implements filter method for relevance scores.\n\"\"\"\nimport torch\n\n\ndef relevance_filter(r: torch.tensor, top_k_percent: float = 1.0) -> torch.tensor:\n    \"\"\"Filter that allows largest k percent values to pass for each batch dimension.\n\n    Filter keeps k% of the largest tensor elements. Other tensor elements are set to\n    zero. Here, k = 1 means that all relevance scores are passed on to the next layer.\n\n    Args:\n        r: Tensor holding relevance scores of current layer.\n        top_k_percent: Proportion of top k values that is passed on.\n\n    Returns:\n        Tensor of same shape as input tensor.\n\n    \"\"\"\n    assert 0.0 < top_k_percent <= 1.0\n\n    if top_k_percent < 1.0:\n        size = r.size()\n        r = r.flatten(start_dim=1)\n        num_elements = r.size(-1)\n        k = max(1, int(top_k_percent * num_elements))\n        top_k = torch.topk(input=r, k=k, dim=-1)\n        r = torch.zeros_like(r)\n        r.scatter_(dim=1, index=top_k.indices, src=top_k.values)\n        return r.view(size)\n    else:\n        return r","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:49:30.873371Z","iopub.execute_input":"2023-12-04T12:49:30.873758Z","iopub.status.idle":"2023-12-04T12:49:32.298312Z","shell.execute_reply.started":"2023-12-04T12:49:30.873719Z","shell.execute_reply":"2023-12-04T12:49:32.297250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LRP layers","metadata":{}},{"cell_type":"code","source":"\"\"\"Layers for layer-wise relevance propagation.\n\nLayers for layer-wise relevance propagation can be modified.\n\n\"\"\"\nimport torch\nfrom torch import nn\n\n\nclass RelevancePropagationAdaptiveAvgPool2d(nn.Module):\n    \"\"\"Layer-wise relevance propagation for 2D adaptive average pooling.\n\n    Attributes:\n        layer: 2D adaptive average pooling layer.\n        eps: A value added to the denominator for numerical stability.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        layer: torch.nn.AdaptiveAvgPool2d,\n        eps: float = 1.0e-05,\n        top_k: float = 0.0,\n    ) -> None:\n        super().__init__()\n        self.layer = layer\n        self.eps = eps\n        self.top_k = top_k\n\n    def forward(self, a: torch.tensor, r: torch.tensor) -> torch.tensor:\n        if self.top_k:\n            r = relevance_filter(r, top_k_percent=self.top_k)\n        z = self.layer.forward(a) + self.eps\n        s = (r / z).data\n        (z * s).sum().backward()\n        c = a.grad\n        r = (a * c).data\n        return r\n\n\nclass RelevancePropagationAvgPool2d(nn.Module):\n    \"\"\"Layer-wise relevance propagation for 2D average pooling.\n\n    Attributes:\n        layer: 2D average pooling layer.\n        eps: A value added to the denominator for numerical stability.\n\n    \"\"\"\n\n    def __init__(\n        self, layer: torch.nn.AvgPool2d, eps: float = 1.0e-05, top_k: float = 0.0\n    ) -> None:\n        super().__init__()\n        self.layer = layer\n        self.eps = eps\n        self.top_k = top_k\n\n    def forward(self, a: torch.tensor, r: torch.tensor) -> torch.tensor:\n        if self.top_k:\n            r = relevance_filter(r, top_k_percent=self.top_k)\n        z = self.layer.forward(a) + self.eps\n        s = (r / z).data\n        (z * s).sum().backward()\n        c = a.grad\n        r = (a * c).data\n        return r\n\n\nclass RelevancePropagationMaxPool2d(nn.Module):\n    \"\"\"Layer-wise relevance propagation for 2D max pooling.\n\n    Optionally substitutes max pooling by average pooling layers.\n\n    Attributes:\n        layer: 2D max pooling layer.\n        eps: a value added to the denominator for numerical stability.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        layer: torch.nn.MaxPool2d,\n        mode: str = \"avg\",\n        eps: float = 1.0e-05,\n        top_k: float = 0.0,\n    ) -> None:\n        super().__init__()\n\n        if mode == \"avg\":\n            self.layer = torch.nn.AvgPool2d(kernel_size=(2, 2))\n        elif mode == \"max\":\n            self.layer = layer\n\n        self.eps = eps\n        self.top_k = top_k\n\n    def forward(self, a: torch.tensor, r: torch.tensor) -> torch.tensor:\n        if self.top_k:\n            r = relevance_filter(r, top_k_percent=self.top_k)\n        z = self.layer.forward(a) + self.eps\n        s = (r / z).data\n        (z * s).sum().backward()\n        c = a.grad\n        r = (a * c).data\n        return r\n\n\nclass RelevancePropagationConv2d(nn.Module):\n    \"\"\"Layer-wise relevance propagation for 2D convolution.\n\n    Optionally modifies layer weights according to propagation rule. Here z^+-rule\n\n    Attributes:\n        layer: 2D convolutional layer.\n        eps: a value added to the denominator for numerical stability.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        layer: torch.nn.Conv2d,\n        mode: str = \"z_plus\",\n        eps: float = 1.0e-05,\n        top_k: float = 0.0,\n    ) -> None:\n        super().__init__()\n\n        self.layer = layer\n\n        if mode == \"z_plus\":\n            self.layer.weight = torch.nn.Parameter(self.layer.weight.clamp(min=0.0))\n            self.layer.bias = torch.nn.Parameter(torch.zeros_like(self.layer.bias))\n\n        self.eps = eps\n        self.top_k = top_k\n\n    def forward(self, a: torch.tensor, r: torch.tensor) -> torch.tensor:\n        if self.top_k:\n            r = relevance_filter(r, top_k_percent=self.top_k)\n        z = self.layer.forward(a) + self.eps\n        s = (r / z).data\n        (z * s).sum().backward()\n        c = a.grad\n        r = (a * c).data\n        return r\n\n\nclass RelevancePropagationLinear(nn.Module):\n    \"\"\"Layer-wise relevance propagation for linear transformation.\n\n    Optionally modifies layer weights according to propagation rule. Here z^+-rule\n\n    Attributes:\n        layer: linear transformation layer.\n        eps: a value added to the denominator for numerical stability.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        layer: torch.nn.Linear,\n        mode: str = \"z_plus\",\n        eps: float = 1.0e-05,\n        top_k: float = 0.0,\n    ) -> None:\n        super().__init__()\n\n        self.layer = layer\n\n        if mode == \"z_plus\":\n            self.layer.weight = torch.nn.Parameter(self.layer.weight.clamp(min=0.0))\n            self.layer.bias = torch.nn.Parameter(torch.zeros_like(self.layer.bias))\n\n        self.eps = eps\n        self.top_k = top_k\n\n    @torch.no_grad()\n    def forward(self, a: torch.tensor, r: torch.tensor) -> torch.tensor:\n        if self.top_k:\n            r = relevance_filter(r, top_k_percent=self.top_k)\n        z = self.layer.forward(a) + self.eps\n        s = r / z\n        c = torch.mm(s, self.layer.weight)\n        r = (a * c).data\n        return r\n\n\nclass RelevancePropagationFlatten(nn.Module):\n    \"\"\"Layer-wise relevance propagation for flatten operation.\n\n    Attributes:\n        layer: flatten layer.\n\n    \"\"\"\n\n    def __init__(self, layer: torch.nn.Flatten, top_k: float = 0.0) -> None:\n        super().__init__()\n        self.layer = layer\n\n    @torch.no_grad()\n    def forward(self, a: torch.tensor, r: torch.tensor) -> torch.tensor:\n        r = r.view(size=a.shape)\n        return r\n\n\nclass RelevancePropagationReLU(nn.Module):\n    \"\"\"Layer-wise relevance propagation for ReLU activation.\n\n    Passes the relevance scores without modification. Might be of use later.\n\n    \"\"\"\n\n    def __init__(self, layer: torch.nn.ReLU, top_k: float = 0.0) -> None:\n        super().__init__()\n\n    @torch.no_grad()\n    def forward(self, a: torch.tensor, r: torch.tensor) -> torch.tensor:\n        return r\n\n\nclass RelevancePropagationDropout(nn.Module):\n    \"\"\"Layer-wise relevance propagation for dropout layer.\n\n    Passes the relevance scores without modification. Might be of use later.\n\n    \"\"\"\n\n    def __init__(self, layer: torch.nn.Dropout, top_k: float = 0.0) -> None:\n        super().__init__()\n\n    @torch.no_grad()\n    def forward(self, a: torch.tensor, r: torch.tensor) -> torch.tensor:\n        return r\n\n\nclass RelevancePropagationIdentity(nn.Module):\n    \"\"\"Identity layer for relevance propagation.\n\n    Passes relevance scores without modifying them.\n\n    \"\"\"\n\n    def __init__(self, layer: nn.Module, top_k: float = 0.0) -> None:\n        super().__init__()\n\n    @torch.no_grad()\n    def forward(self, a: torch.tensor, r: torch.tensor) -> torch.tensor:\n        return r","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:49:32.300044Z","iopub.execute_input":"2023-12-04T12:49:32.300360Z","iopub.status.idle":"2023-12-04T12:49:32.340506Z","shell.execute_reply.started":"2023-12-04T12:49:32.300331Z","shell.execute_reply":"2023-12-04T12:49:32.339480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"UTILS","metadata":{}},{"cell_type":"code","source":"\"\"\"Script with helper function.\"\"\"\n\n\ndef layers_lookup() -> dict:\n    \"\"\"Lookup table to map network layer to associated LRP operation.\n\n    Returns:\n        Dictionary holding class mappings.\n    \"\"\"\n    lookup_table = {\n        torch.nn.modules.linear.Linear: RelevancePropagationLinear,\n        torch.nn.modules.conv.Conv2d: RelevancePropagationConv2d,\n        torch.nn.modules.activation.ReLU: RelevancePropagationReLU,\n        torch.nn.modules.dropout.Dropout: RelevancePropagationDropout,\n        torch.nn.modules.flatten.Flatten: RelevancePropagationFlatten,\n        torch.nn.modules.pooling.AvgPool2d: RelevancePropagationAvgPool2d,\n        torch.nn.modules.pooling.MaxPool2d: RelevancePropagationMaxPool2d,\n        torch.nn.modules.pooling.AdaptiveAvgPool2d: RelevancePropagationAdaptiveAvgPool2d,\n    }\n    return lookup_table","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:49:32.341891Z","iopub.execute_input":"2023-12-04T12:49:32.342240Z","iopub.status.idle":"2023-12-04T12:49:32.353121Z","shell.execute_reply.started":"2023-12-04T12:49:32.342212Z","shell.execute_reply":"2023-12-04T12:49:32.352072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LRP model","metadata":{}},{"cell_type":"code","source":"\"\"\"Class for layer-wise relevance propagation.\n\nLayer-wise relevance propagation for VGG-like networks from PyTorch's Model Zoo.\nImplementation can be adapted to work with other architectures as well by adding the corresponding operations.\n\n    Typical usage example:\n\n        model = torchvision.models.vgg16(pretrained=True)\n        lrp_model = LRPModel(model)\n        r = lrp_model.forward(x)\n\n\"\"\"\nfrom copy import deepcopy\n\nimport torch\nfrom torch import nn\n\n\n\nclass LRPModel(nn.Module):\n    \"\"\"Class wraps PyTorch model to perform layer-wise relevance propagation.\"\"\"\n\n    def __init__(self, model: torch.nn.Module, top_k: float = 0.0) -> None:\n        super().__init__()\n        self.model = model\n        self.top_k = top_k\n\n        self.model.eval()  # self.model.train() activates dropout / batch normalization etc.!\n\n        # Parse network\n        self.layers = self._get_layer_operations()\n\n        # Create LRP network\n        self.lrp_layers = self._create_lrp_model()\n\n    def _create_lrp_model(self) -> torch.nn.ModuleList:\n        \"\"\"Method builds the model for layer-wise relevance propagation.\n\n        Returns:\n            LRP-model as module list.\n\n        \"\"\"\n        # Clone layers from original model. This is necessary as we might modify the weights.\n        layers = deepcopy(self.layers)\n        lookup_table = layers_lookup()\n\n        # Run backwards through layers\n        for i, layer in enumerate(layers[::-1]):\n            try:\n                layers[i] = lookup_table[layer.__class__](layer=layer, top_k=self.top_k)\n            except KeyError:\n                message = (\n                    f\"Layer-wise relevance propagation not implemented for \"\n                    f\"{layer.__class__.__name__} layer.\"\n                )\n                raise NotImplementedError(message)\n\n        return layers\n\n    def _get_layer_operations(self) -> torch.nn.ModuleList:\n        \"\"\"Get all network operations and store them in a list.\n\n        This method is adapted to VGG networks from PyTorch's Model Zoo.\n        Modify this method to work also for other networks.\n\n        Returns:\n            Layers of original model stored in module list.\n\n        \"\"\"\n        layers = torch.nn.ModuleList()\n\n        # Parse VGG-16\n        for layer in self.model.features:\n            layers.append(layer)\n\n        layers.append(self.model.avgpool)\n        layers.append(torch.nn.Flatten(start_dim=1))\n\n        for layer in self.model.classifier:\n            layers.append(layer)\n\n        return layers\n\n    def forward(self, x: torch.tensor) -> torch.tensor:\n        \"\"\"Forward method that first performs standard inference followed by layer-wise relevance propagation.\n\n        Args:\n            x: Input tensor representing an image / images (N, C, H, W).\n\n        Returns:\n            Tensor holding relevance scores with dimensions (N, 1, H, W).\n\n        \"\"\"\n        activations = list()\n\n        # Run inference and collect activations.\n        with torch.no_grad():\n            # Replace image with ones avoids using image information for relevance computation.\n            activations.append(torch.ones_like(x))\n            for layer in self.layers:\n                x = layer.forward(x)\n                activations.append(x)\n\n        # Reverse order of activations to run backwards through model\n        activations = activations[::-1]\n        activations = [a.data.requires_grad_(True) for a in activations]\n\n        # Initial relevance scores are the network's output activations\n        relevance = torch.softmax(activations.pop(0), dim=-1)  # Unsupervised\n\n        # Perform relevance propagation\n        for i, layer in enumerate(self.lrp_layers):\n            relevance = layer.forward(activations.pop(0), relevance)\n\n        return relevance.permute(0, 2, 3, 1).sum(dim=-1).squeeze().detach().cpu()","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:49:32.354448Z","iopub.execute_input":"2023-12-04T12:49:32.354755Z","iopub.status.idle":"2023-12-04T12:49:32.373829Z","shell.execute_reply.started":"2023-12-04T12:49:32.354728Z","shell.execute_reply":"2023-12-04T12:49:32.372979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nlrp_model = LRPModel(gru_model)\nr = lrp_model.forward(x)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:49:32.374932Z","iopub.execute_input":"2023-12-04T12:49:32.375221Z","iopub.status.idle":"2023-12-04T12:49:32.835519Z","shell.execute_reply.started":"2023-12-04T12:49:32.375195Z","shell.execute_reply":"2023-12-04T12:49:32.834101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"https://github.com/Sara-mibo/LRP_EncoderDecoder_GRU/blob/main/LRP/lrp_function.py","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}